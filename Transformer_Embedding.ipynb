{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa375d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Embedding Shape: (1, 768)\n",
      "Mean Embedding: [[-2.46534258e-01  1.55215949e-01 -3.33123863e-01 -1.15170322e-01\n",
      "  -1.38967335e-02  4.40402441e-02  5.67849541e+00  1.51439518e-01\n",
      "  -2.92459279e-01  1.25109583e-01  4.68287766e-01  3.73245448e-01\n",
      "   1.49615511e-01 -4.41485912e-01 -1.10913053e-01 -2.91135848e-01\n",
      "  -2.99705774e-01  2.13527624e-02 -2.54093379e-01 -1.72143832e-01\n",
      "  -6.60345405e-02  1.39443919e-01 -4.49155897e-01  2.71856189e-01\n",
      "  -2.09399968e-01 -6.21943362e-02 -3.93749118e-01 -1.01555586e-01\n",
      "  -5.67435510e-02  3.31536308e-02 -2.62225658e-01  4.45141969e-03\n",
      "  -1.39230475e-01 -2.13647753e-01 -1.57585308e-01 -3.23703647e-01\n",
      "   6.64620895e+01  1.33286282e-01  2.43868423e-03  7.48879492e-01\n",
      "  -3.46334055e-02 -3.43357205e-01 -9.38073918e-02 -5.40846400e-02\n",
      "  -3.04617316e-01 -2.39816815e-01 -1.05470829e-01  1.88021045e-02\n",
      "  -4.51870821e-02  8.07366788e-01  1.75010890e-01 -3.99206758e-01\n",
      "  -4.39740151e-01  3.14695209e-01 -1.25587448e-01  2.02625424e-01\n",
      "  -2.09220931e-01 -2.66584814e-01  4.82102893e-02  1.32038206e-01\n",
      "   3.70784909e-01 -5.76420903e-01 -3.38015497e-01  5.76321542e-01\n",
      "  -1.10510254e+00 -2.43747190e-01  4.51905727e-02  3.39874476e-01\n",
      "  -5.45256972e-01 -9.94606242e-02 -1.02472439e-01 -1.85093671e-01\n",
      "  -2.51206249e-01  1.64041117e-01  1.98526442e-01 -2.54953057e-01\n",
      "  -1.14384390e-01 -2.29334131e-01  2.06842989e-01 -9.76767614e-02\n",
      "  -1.40389457e-01 -1.67826831e-01  2.89843172e-01 -9.23801307e-03\n",
      "  -1.87368721e-01  1.95963189e-01 -3.78533095e-01 -1.02411020e+00\n",
      "  -8.40710104e-02  2.22565364e-02  2.46347502e-01  2.54571158e-02\n",
      "  -5.67215271e-02 -2.26343781e-01 -2.36656845e-01 -1.11215472e-01\n",
      "  -3.36749434e-01 -3.86597276e-01 -1.87481251e-02 -1.00758679e-01\n",
      "   7.21505657e-02  1.83492884e-01  8.43656838e-01  1.12742167e-02\n",
      "   3.98375124e-01  6.50438741e-02 -1.17482565e-01  1.97227716e+00\n",
      "  -2.74652094e-01 -2.94774532e-01  4.80787843e-01 -9.16958600e-02\n",
      "  -4.74271439e-02 -3.13104808e-01  2.44246542e-01 -1.35554254e-01\n",
      "   1.35947391e-01  3.62952143e-01  3.12731653e-01 -4.23408747e-02\n",
      "  -3.26799601e-01  4.89086896e-01 -1.65005356e-01  1.43803373e-01\n",
      "   9.98666659e-02 -2.29529917e-01  6.04159199e-02 -3.55681717e-01\n",
      "  -1.29317388e-01 -2.04592809e-01 -8.38939250e-02 -1.73796654e-01\n",
      "  -4.38998252e-01  3.85100186e-01  2.13809595e-01  1.31185204e-01\n",
      "  -5.50122797e-01  4.35574055e-01  5.40474474e-01  2.77501613e-01\n",
      "   1.58046827e-01  2.49628082e-01  3.21861535e-01 -1.66023329e-01\n",
      "   4.72094491e-02  7.60707080e-01 -1.25140771e-01 -3.57102185e-01\n",
      "  -8.15936103e-02  2.87304550e-01  2.73724914e-01  2.42048681e-01\n",
      "  -2.34646544e-01 -3.72058988e-01  2.47266814e-02 -3.11091244e-01\n",
      "   1.57493263e-01  9.99825075e-03 -1.36181653e-01 -2.10955665e-01\n",
      "  -1.91826761e-01 -2.28974789e-01  9.57563147e-03  2.39149332e-02\n",
      "  -1.43674403e-01 -3.75692278e-01  2.96809599e-02 -2.53178096e+00\n",
      "  -4.62211482e-03 -9.47134104e-03  2.33368292e-01  9.81138647e-02\n",
      "  -7.85592496e-02 -3.41667622e-01 -3.23756754e-01  2.55805939e-01\n",
      "  -3.74700762e-02  1.83183905e-02 -1.27237355e-02 -3.85240197e-01\n",
      "  -3.32413375e-01 -2.88656335e-02 -6.45826235e-02 -5.56069136e-01\n",
      "  -1.81518853e-01 -2.28806764e-01  2.70251930e-01 -5.82597032e-02\n",
      "  -8.97651389e-02 -8.64856914e-02  8.02229419e-02  5.42227961e-02\n",
      "  -2.51926333e-01 -3.40059072e-01 -3.09110396e-02  4.42272544e-01\n",
      "   3.59485596e-01 -3.58158231e-01  1.93539038e-01  1.88507766e-01\n",
      "   1.95262685e-01  1.32100284e-01  1.04224063e-01  2.23827437e-01\n",
      "  -4.82450202e-02 -1.69309318e-01  2.64927018e-02 -3.71147364e-01\n",
      "   4.12566103e-02  4.07136455e-02  4.37211066e-01  1.49950847e-01\n",
      "  -3.01934749e-01 -1.32147089e-01 -8.78668725e-02 -2.32540444e-01\n",
      "   2.88714021e-01  1.16545133e-01  1.02006895e-02  3.51293564e-01\n",
      "  -1.01482913e-01 -2.55172908e-01  1.84090391e-01  7.11352766e-01\n",
      "   6.39217719e-02  6.27595901e-01 -4.52622890e-01 -1.98135555e-01\n",
      "   3.44365090e-02 -3.76809649e-02  5.15551791e-02  1.52716696e-01\n",
      "   1.74473393e+00  2.46621817e-01  2.50372231e-01  2.67650306e-01\n",
      "   3.19099277e-02 -1.37027264e-01 -1.32349893e-01  4.65811133e-01\n",
      "  -1.79673761e-01 -3.86987776e-02 -2.42219970e-01 -3.96355093e-01\n",
      "   3.18148471e-02  1.79743081e-01 -1.55028611e-01 -3.54961812e-01\n",
      "   9.95003991e-03  2.19518378e-01 -4.74767864e-01  2.00810656e-01\n",
      "   3.30824733e-01  3.93274516e-01 -2.18068495e-01  7.54583597e-01\n",
      "   2.54166991e-01 -2.31940555e-03 -2.56138891e-01  6.42802596e-01\n",
      "   2.82682091e-01  4.29549694e-01 -8.74033347e-02  3.26788455e-01\n",
      "   9.53435078e-02  1.90665826e-01 -1.01370871e+00  9.16725025e-03\n",
      "  -1.54311240e-01 -4.91647154e-01 -2.52192259e-01  2.24237776e+00\n",
      "  -8.21058527e-02  3.31262313e-02  2.64248908e-01 -3.44978720e-01\n",
      "  -2.14800030e-01  6.64479751e-03 -3.48591395e-02  1.09521151e-02\n",
      "   2.40875676e-01  1.60272181e-01  1.72450975e-01  1.58191040e-01\n",
      "  -1.67348459e-01 -1.81697216e-02  3.54599833e-01 -1.67789117e-01\n",
      "   4.14075583e-01 -2.65534520e-01  6.29079759e-01 -1.59906864e-01\n",
      "   4.00734842e-01  2.42015943e-01  2.53203660e-01  1.05881132e-02\n",
      "   1.62939459e-01 -3.04215312e-01 -4.10568826e-02  1.82137564e-01\n",
      "  -5.43913879e-02  2.28714459e-02 -2.58220851e-01  3.20546001e-01\n",
      "   2.35330760e-01 -7.17450539e-03 -3.28658998e-01 -1.67568266e-01\n",
      "   3.54006514e-02 -5.14751971e-01  2.51061976e-01 -6.67300895e-02\n",
      "   5.26542544e-01 -1.57592326e-01 -3.09028015e+01 -1.90872811e-02\n",
      "   6.25247955e-02  7.08520830e-01 -3.46263528e-01  6.72739744e-01\n",
      "  -7.19718099e-01  1.18383966e-01 -2.25957319e-01  2.81887591e-01\n",
      "  -4.14088339e-01  5.16972661e-01 -9.98651236e-02  7.39168152e-02\n",
      "   6.31015897e-01 -2.31716380e-01 -3.10426235e-01  2.99058080e-01\n",
      "   6.33550763e-01  4.48445976e-01 -4.59517568e-01  2.52557784e-01\n",
      "   1.19627632e-01 -1.58364903e-02 -6.57887980e-02 -3.25654119e-01\n",
      "   1.55803621e-01  7.79100507e-02 -4.94070128e-02  1.20960429e-01\n",
      "   4.70305085e-01 -4.62947041e-02  7.81652108e-02  5.92015423e-02\n",
      "  -1.25042826e-01 -2.39897639e-01 -7.84062222e-02  5.66321723e-02\n",
      "  -1.26181871e-01 -3.64659250e-01  1.95507541e-01  3.18800770e-02\n",
      "   6.73986897e-02  3.49483669e-01 -1.41765907e-01 -2.96081245e-01\n",
      "  -2.93711483e-01 -6.01575434e-01  5.38973093e-01  1.26911458e-02\n",
      "  -1.25987500e-01 -4.98199850e-01 -1.41914830e-01 -8.21873620e-02\n",
      "   8.73641223e-02 -9.53074992e-02  2.91111857e-01  6.48573460e-03\n",
      "  -7.40356088e-01 -1.15262091e+00 -7.13960505e+00  1.43904939e-01\n",
      "  -1.97806865e-01  3.78269792e-01 -5.73371053e-01 -2.69163698e-01\n",
      "   1.85307607e-01  1.03267603e-01 -2.28613585e-01 -5.53520247e-02\n",
      "  -5.55700481e-01  3.29666324e-02 -3.91369522e-01  3.15650672e-01\n",
      "   1.01972364e-01  1.66581824e-01 -6.68503404e-01 -5.06745636e-01\n",
      "  -2.16041639e-01 -2.96481639e-01  2.17500240e-01 -8.66062641e-02\n",
      "   5.19786596e-01 -7.13173300e-02  1.91154424e-02  2.24591017e-01\n",
      "   3.50916803e-01 -3.01002115e-01 -1.88498467e-01  4.28280294e-01\n",
      "   3.29948142e-02  2.13607818e-01  6.51756376e-02 -2.57058024e-01\n",
      "   2.57743025e+00 -1.90983832e-01 -2.60210931e-01  5.02548754e-01\n",
      "   1.04687899e-01 -7.34691799e-01 -4.38410714e-02  6.71337545e-01\n",
      "  -1.00379460e-01  1.19573221e-01  2.09707439e-01  1.43469438e-01\n",
      "  -9.54377592e-01  3.72558623e-03  1.59991369e-01 -7.48806149e-02\n",
      "   2.24257812e-01  2.33781472e-01  1.45826653e-01  2.76156645e-02\n",
      "  -1.77718595e-01  5.38879037e-02  7.72130814e+01 -1.20285258e-01\n",
      "  -3.19898695e-01 -1.85350001e-01  3.06026012e-01 -5.07117435e-02\n",
      "   1.58229366e-01 -1.08020827e-01  1.59490556e-01  1.31267858e+00\n",
      "   2.03194618e-01 -2.45521054e-01  3.00155759e+00 -5.41746020e-02\n",
      "   7.75963515e-02  1.04881160e-01 -7.50479877e-01  1.10229492e+00\n",
      "  -8.05125386e-02 -1.20717727e-01  4.07334790e-02 -2.32386544e-01\n",
      "   1.78042099e-01 -3.34306300e-01  7.58096352e-02  1.01356757e+00\n",
      "  -4.52331841e-01  1.84064791e-01 -5.69494590e-02 -3.50224912e-01\n",
      "   1.63735539e-01  1.46674335e-01  2.76792884e-01 -2.36180335e-01\n",
      "  -3.02161872e-01  3.05993915e-01  6.72631711e-02 -2.43279949e-01\n",
      "  -3.15964431e-01  2.90253222e-01 -3.54255944e-01  1.68413088e-01\n",
      "  -1.09716840e-01 -2.36312255e-01  1.44244954e-01  6.09752424e-02\n",
      "   9.56718624e-02  1.36515483e-01 -4.61528003e-01 -1.76653683e+00\n",
      "  -8.92690361e-01  1.14300311e+00  1.46268338e-01  2.79239327e-01\n",
      "  -2.33502954e-01  3.87212522e-02  3.04912239e-01 -3.70683610e-01\n",
      "   5.02183020e-01 -8.66760164e-02 -4.06375557e-01  3.78417462e-01\n",
      "  -1.42126903e-01  2.06151064e-02 -2.51083910e-01 -4.64006269e-04\n",
      "   1.80587250e+02 -1.98477253e-01  1.90430000e-01  2.27772906e-01\n",
      "  -2.27690618e-02  7.46288449e-02 -3.19800407e-01 -1.31056428e+00\n",
      "  -2.83791721e-01 -1.38837084e-01 -1.10778578e-01 -2.10912842e-02\n",
      "   2.58175075e-01  3.73286784e-01  4.35147882e-02  3.37785214e-01\n",
      "   4.31264728e-01 -4.39864159e-01 -4.66292381e-01 -2.98406214e-01\n",
      "   3.06973886e-02  1.22895695e-01 -5.07060170e-01 -6.83117807e-02\n",
      "   9.33679864e-02  2.24944204e-01 -5.65777063e-01 -4.34603952e-02\n",
      "   5.10392368e-01  9.98410642e-01 -7.26042032e-01  3.18412073e-02\n",
      "   2.98973411e-01 -3.77909482e-01  5.76484688e-02  1.69982165e-01\n",
      "   5.09364188e-01 -1.07642159e-01 -1.51060134e-01  3.22634190e-01\n",
      "   1.85375416e-03 -1.01971082e-01 -5.88482440e-01  2.21285284e-01\n",
      "   5.72800279e-01 -1.04133962e-02 -1.94831520e-01 -1.11313248e+00\n",
      "   4.02381122e-01  4.61834997e-01  1.25330389e-01 -3.95013168e-02\n",
      "   4.60766524e-01  1.30743653e-01  9.61406901e-02  2.60893732e-01\n",
      "   1.94534495e-01 -2.55387202e-02 -5.55031657e-01  1.41585961e-01\n",
      "   6.04866035e-02 -2.94268489e-01 -9.26993042e-02 -2.04232782e-01\n",
      "   2.42608607e-01  7.18166679e-02 -4.16618735e-02 -2.45572299e-01\n",
      "  -3.76307696e-01 -3.14802736e-01  3.10468048e-01 -3.41052562e-01\n",
      "   6.43418357e-02  6.17714114e-02 -8.52452815e-02  3.64026666e-01\n",
      "  -1.77669749e-01 -5.80388643e-02 -2.42643058e-01  1.93851307e-01\n",
      "  -4.24055266e-04 -9.41218063e-02  1.00612842e-01  1.37466699e-01\n",
      "  -1.24893412e-01 -1.32805303e-01  1.25181302e-01 -1.23569183e-01\n",
      "   2.72680461e-01  2.27249011e-01  4.32060100e-02  5.96591225e-03\n",
      "  -4.34422828e-02  1.75756633e-01  2.82476038e-01 -4.33107346e-01\n",
      "  -1.89000219e-01  3.73753488e-01  1.70126662e-01  4.56649847e-02\n",
      "  -1.01214297e-01 -4.90148254e-02  3.22779596e-01  2.48509988e-01\n",
      "  -5.55258930e-01  2.19149962e-01 -8.52223858e-02  1.72302946e-01\n",
      "   2.76372701e-01  1.97976716e-02  2.53313839e-01 -8.31164345e-02\n",
      "  -4.65959460e-02 -1.45801321e-01  1.73811212e-01  1.75758794e-01\n",
      "   1.52629301e-01  6.31530061e-02 -3.13261777e-01  4.13112231e-02\n",
      "   6.24326356e-02 -1.18513040e-01 -8.43127966e-02 -5.39955914e-01\n",
      "  -2.41017025e-02 -1.04716733e-01 -1.89125717e-01  2.98871487e-01\n",
      "  -1.03889443e-01 -3.25434774e-01 -2.81755716e-01 -2.62427592e+00\n",
      "  -6.60932041e-04 -2.57546157e-01  7.37881362e-01 -6.97563738e-02\n",
      "   4.86539565e-02 -3.35628986e-01  3.15233111e-01 -8.92948031e-01\n",
      "  -1.57360896e-01 -1.45807445e-01  1.46653339e-01  2.67428249e-01\n",
      "   1.99148744e-01 -1.04829080e-01 -3.33848111e-02  1.18138216e-01\n",
      "  -2.27026537e-01  7.24863932e-02 -2.91521281e-01 -9.43630934e-03\n",
      "   4.81841087e-01  6.13511652e-02 -3.38266551e-01  2.03933433e-01\n",
      "  -3.27391118e-01 -2.15823084e-01 -3.12743574e-01  5.41070402e-01\n",
      "  -1.02015167e-01  5.87092005e-02  2.70659141e-02  3.12769413e-01\n",
      "  -5.66923022e-02  2.67973721e-01 -2.94498298e-02 -2.55308628e-01\n",
      "   1.78406641e-01  1.46496937e-01 -1.61512122e-01  6.40016720e-02\n",
      "   1.06187247e-01 -1.66093335e-01 -5.50496280e-01 -4.18962806e-01\n",
      "  -2.04982743e-01  1.66773349e-01 -6.02304578e-01 -3.06043327e-01\n",
      "  -1.55621141e-01  1.63293093e-01  1.74015790e-01  5.38883746e-01\n",
      "  -1.03062582e+00 -8.37436598e-03  1.91721991e-01  5.65967038e-02\n",
      "   3.23962085e-02 -4.81836915e-01  1.54333815e-01 -2.44427532e-01\n",
      "  -1.99516252e-01 -1.18008412e-01 -1.52082160e-01  4.23849791e-01\n",
      "  -1.83342800e-01 -2.46064261e-01 -2.87028491e-01 -1.63161606e-01\n",
      "  -5.17632142e-02  3.34346235e-01  3.92661214e-01 -1.94318280e-01\n",
      "   6.16750903e-02 -6.57173216e-01  1.20110705e-01 -2.26086259e+00\n",
      "  -3.38372588e-01  1.00823589e-01  1.26521038e-02 -1.80149525e-01\n",
      "  -1.77875102e-01 -3.48838180e-01  4.12484854e-01 -1.56351775e-01\n",
      "  -4.11613077e-01 -3.69399071e-01  1.93515256e-01 -7.94569775e-02\n",
      "   8.42899308e-02  1.94087952e-01  2.86514908e-01  7.69967288e-02\n",
      "   1.41192511e-01  2.90561505e-02 -3.74131471e-01  1.30417123e-01\n",
      "   6.93869665e-02 -1.35406688e-01  4.28578965e-02  8.73752087e-02\n",
      "   7.53378719e-02  9.34108496e-02  3.01037759e-01 -3.05950731e-01\n",
      "   1.81197837e-01 -6.38246834e-02  3.81842144e-02  1.06623314e-01\n",
      "  -2.21605927e-01 -2.91778982e-01 -5.69944084e-01 -2.30298251e-01\n",
      "  -2.84997560e-02 -2.78274804e-01  6.77010238e-01 -1.95660740e-01\n",
      "   3.82534921e-01 -8.36998522e-01 -6.20008171e-01  4.93112728e-02\n",
      "   2.34106109e-02  2.49187201e-01 -1.52322575e-01  1.12689577e-01\n",
      "   2.83160567e-01 -3.80716383e-01 -4.65920903e-02 -1.96045309e-01\n",
      "   2.42306069e-02 -3.77219588e-01  1.16345137e-01  7.18053520e-01\n",
      "   1.85573712e-01 -6.64881766e-02  2.44511199e+00 -3.52523983e-01\n",
      "   3.11916679e-01  1.39735356e-01  2.81048685e-01 -7.10796043e-02]]\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2Model\n",
    "import torch\n",
    "\n",
    "# Load the GPT-2 tokenizer and model\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "model = GPT2Model.from_pretrained(\"gpt2\")\n",
    "\n",
    "# Set the padding token\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Example medical transcript\n",
    "medical_transcript = \"Patient presented with symptoms of fever and cough. Diagnosis revealed pneumonia.\"\n",
    "\n",
    "# Tokenize the medical transcript\n",
    "inputs = tokenizer(medical_transcript, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "# Forward pass through the model\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "# Get the embeddings of the last hidden layer\n",
    "last_hidden_states = outputs.last_hidden_state\n",
    "\n",
    "# Calculate the mean embedding across all tokens\n",
    "mean_embedding = torch.mean(last_hidden_states, dim=1)\n",
    "\n",
    "# Convert the mean embedding to a numpy array\n",
    "mean_embedding_numpy = mean_embedding.numpy()\n",
    "\n",
    "print(\"Mean Embedding Shape:\", mean_embedding_numpy.shape)\n",
    "print(\"Mean Embedding:\", mean_embedding_numpy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1222b320",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Sentence Embeddings: (3, 768)\n",
      "[[-0.41188726  0.19563177 -0.21300343 ... -0.39615563 -0.17174609\n",
      "  -0.19250548]\n",
      " [-0.16289961 -0.1759688  -0.30027658 ... -0.22405262  0.1804233\n",
      "  -0.08022095]\n",
      " [-0.09802145  0.09829926  0.1123988  ... -0.47010767 -0.16395707\n",
      "   0.07442835]]\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Sample medical transcript\n",
    "medical_transcript = [\n",
    "    \"Patient presented with symptoms of cough and shortness of breath.\",\n",
    "    \"Physical examination revealed elevated temperature and wheezing.\",\n",
    "    \"Diagnosis confirmed as bronchitis, prescribed antibiotics and inhaler.\"\n",
    "]\n",
    "\n",
    "# Load pre-trained BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Tokenize and encode the medical transcript\n",
    "inputs = tokenizer(medical_transcript, return_tensors='pt', padding=True, truncation=True)\n",
    "\n",
    "# Pass the encoded transcript through the model\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "# Extract embeddings from the last hidden states of the model\n",
    "embeddings = outputs.last_hidden_state\n",
    "\n",
    "# Average the embeddings for each token to get sentence-level embeddings\n",
    "sentence_embeddings = np.mean(embeddings.numpy(), axis=1)\n",
    "\n",
    "# Print the shape of the sentence embeddings\n",
    "print(\"Shape of Sentence Embeddings:\", sentence_embeddings.shape)\n",
    "\n",
    "print(sentence_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb71364f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetModel: ['lm_loss.weight', 'lm_loss.bias']\n",
      "- This IS expected if you are initializing XLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Sentence Embeddings: (3, 768)\n",
      "[[-0.784388    1.136335   -1.4560485  ... -1.3636625  -0.02272269\n",
      "   0.945049  ]\n",
      " [ 1.9143348   2.7174098  -1.2326441  ... -0.5918026   1.250938\n",
      "   1.0457697 ]\n",
      " [-0.06876998  1.707028   -3.581354   ...  0.13654473 -0.00410832\n",
      "   0.49695683]]\n"
     ]
    }
   ],
   "source": [
    "from transformers import XLNetTokenizer, XLNetModel\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Sample medical transcript\n",
    "medical_transcript = [\n",
    "    \"Patient presented with symptoms of cough and shortness of breath.\",\n",
    "    \"Physical examination revealed elevated temperature and wheezing.\",\n",
    "    \"Diagnosis confirmed as bronchitis, prescribed antibiotics and inhaler.\"\n",
    "]\n",
    "\n",
    "# Load pre-trained XLNet tokenizer and model\n",
    "tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased')\n",
    "model = XLNetModel.from_pretrained('xlnet-base-cased')\n",
    "\n",
    "# Tokenize and encode the medical transcript\n",
    "inputs = tokenizer(medical_transcript, return_tensors='pt', padding=True, truncation=True)\n",
    "\n",
    "# Pass the encoded transcript through the model\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "# Extract embeddings from the last hidden states of the model\n",
    "embeddings = outputs.last_hidden_state\n",
    "\n",
    "# Average the embeddings for each token to get sentence-level embeddings\n",
    "sentence_embeddings = np.mean(embeddings.numpy(), axis=1)\n",
    "\n",
    "# Print the shape of the sentence embeddings\n",
    "print(\"Shape of Sentence Embeddings:\", sentence_embeddings.shape)\n",
    "\n",
    "print(sentence_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "964405e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81e88e4360ec428997706b214c85c526",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)\"spiece.model\";:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa1898c901b2468a81f4599271b70c51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)enizer_config.json\";:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d943bb5793f84855a4353d9babaf8226",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)\"config.json\";:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62a6e1eb5cfa490289251a2be9ea3d82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/242M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "222090ffe640475aa983e4785bac7801",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ration_config.json\";:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siva7\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\generation\\utils.py:1273: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 20 (`generation_config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Embeddings:\n",
      "physical examination revealed elevated temperature and wheezing.\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Sample medical transcript\n",
    "medical_transcript = [\n",
    "    \"Patient presented with symptoms of cough and shortness of breath.\",\n",
    "    \"Physical examination revealed elevated temperature and wheezing.\",\n",
    "    \"Diagnosis confirmed as bronchitis, prescribed antibiotics and inhaler.\"\n",
    "]\n",
    "\n",
    "# Load pre-trained T5 tokenizer and model\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
    "model = T5ForConditionalGeneration.from_pretrained('t5-small')\n",
    "\n",
    "# Prepare input data for T5\n",
    "input_text = \"summarize: \" + ' '.join(medical_transcript)\n",
    "\n",
    "# Tokenize input text\n",
    "input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "\n",
    "# Generate embeddings using T5\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(input_ids)\n",
    "\n",
    "# Decode the generated embeddings\n",
    "embeddings = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# Print the generated embeddings\n",
    "print(\"Generated Embeddings:\")\n",
    "print(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d33b888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7caac559778341f68fa0c79defa8b091",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)\"vocab.json\";:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "128412505f864c8fb9561f889606a5b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)\"merges.txt\";:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a14f5a0a627476c9f9f16ed4d58df96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)\"config.json\";:   0%|          | 0.00/481 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60e10dca008e4b659f38d978fc314a92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/501M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Embedding Shape: (1, 768)\n",
      "Mean Embedding: [[-1.34657444e-02  8.05886164e-02  9.51291472e-02 -9.36847180e-02\n",
      "   2.95858383e-01  3.12678337e-01  5.81306070e-02  3.27146016e-02\n",
      "   1.52028233e-01 -1.28165603e-01 -1.18035570e-01 -2.30172843e-01\n",
      "   4.93167639e-02 -1.43226296e-01 -3.03018764e-02 -2.88337946e-01\n",
      "   1.23698361e-01 -1.23696536e-01 -2.02867966e-02 -1.61040038e-01\n",
      "  -9.55083445e-02  4.34743837e-02 -2.39905622e-03 -7.56407008e-02\n",
      "  -2.41796114e-02 -5.93555868e-02 -9.40332860e-02  3.65279242e-02\n",
      "   1.42758861e-01 -2.14311540e-01 -1.01221092e-02  6.35195151e-02\n",
      "   1.18025638e-01 -1.30293459e-01 -5.94660733e-03 -5.66560552e-02\n",
      "   1.70334756e-01  9.83177405e-03  1.10045493e-01  6.96563721e-02\n",
      "  -2.35299617e-01 -6.25173151e-02 -6.04168512e-02 -1.25766873e-01\n",
      "  -3.34312469e-02 -2.57791486e-02  2.67696586e-02  3.02116340e-03\n",
      "   8.98886845e-02 -5.48655866e-03 -8.30903426e-02  4.45259474e-02\n",
      "  -4.26012538e-02 -1.17320172e-01 -4.40187305e-02  1.05224088e-01\n",
      "  -6.52815104e-02 -3.56510170e-02 -6.73300624e-02 -4.89724874e-02\n",
      "  -7.17128664e-02  4.45811041e-02 -5.93668297e-02 -4.22724262e-02\n",
      "   4.59637567e-02 -1.16780154e-01 -3.78199480e-02 -2.70886533e-02\n",
      "   7.44115338e-02  1.35711953e-01  8.91045108e-02  2.30874941e-02\n",
      "   2.02849954e-02  4.36154529e-02  5.19527346e-02  1.12189360e-01\n",
      "   4.73761298e-02 -6.25399828e+00  1.51926830e-01  8.14843699e-02\n",
      "  -5.53308167e-02  3.12849917e-02  9.92653549e-01  1.62702039e-01\n",
      "  -7.28413761e-02  1.29745349e-01  2.58321539e-02 -1.06873102e-01\n",
      "  -7.11422712e-02  1.09703736e-02 -3.31897079e-03  3.20996530e-02\n",
      "   4.63505089e-02  2.43122190e-01  1.03107788e-01  1.29480928e-01\n",
      "   2.75633037e-02  8.93472791e-01 -8.05207565e-02  1.26611829e-01\n",
      "   5.06942905e-02 -5.14698923e-02  1.93091989e-01  8.54213461e-02\n",
      "   2.48016641e-02 -1.10675752e-01 -1.01271719e-01 -9.12862178e-03\n",
      "  -6.09659739e-02  2.37561855e-02 -3.34001109e-02 -3.15617956e-02\n",
      "   2.23491956e-02 -3.96610349e-02 -1.07368723e-01  5.44197485e-02\n",
      "   1.14889517e-01  1.46374349e-02  3.90615165e-02 -5.20089525e-04\n",
      "   1.54273929e-02  8.86251777e-02  1.49144530e-01  2.43660319e-03\n",
      "  -7.55009726e-02  7.51105025e-02  3.82998995e-02  2.84279268e-02\n",
      "  -5.10500111e-02  6.91646263e-02  1.01089776e-02 -5.36085904e-01\n",
      "  -5.64959310e-02 -6.24477565e-02 -6.61221668e-02  9.85417515e-04\n",
      "   5.33368587e-02 -2.64952872e-02 -1.15950868e-01  9.43092722e-03\n",
      "   1.29930647e-02  1.17213866e-02 -3.51348706e-02 -8.62957388e-02\n",
      "  -1.65337399e-02  8.24030787e-02 -6.31167740e-02 -2.28933226e-02\n",
      "   1.97192073e-01  3.63403022e-01  9.11369920e-02 -1.42700806e-01\n",
      "  -3.20000425e-02 -7.97441229e-02  5.10742888e-02  6.60768077e-02\n",
      "   1.89199314e-01  3.03037137e-01 -5.88517748e-02  1.87196180e-01\n",
      "   1.57366902e-01 -4.94037792e-02 -3.02864425e-02 -6.83779344e-02\n",
      "   1.89674124e-02  4.24507633e-02  7.39857331e-02  1.40569713e-02\n",
      "  -1.09793404e-02  4.65314575e-02 -2.39248723e-02  6.27537370e-02\n",
      "   4.45648581e-02  1.66738033e-02 -1.41620278e-01  1.38787199e-02\n",
      "   1.81355536e-01  4.49624024e-02  5.13280518e-02  2.08892226e-02\n",
      "  -3.79677117e-02  3.08391023e-02  1.24088926e-02 -9.66371223e-02\n",
      "   1.18311249e-01  5.48229478e-02  9.95929912e-02  1.52617946e-01\n",
      "  -1.56626978e-03 -5.81693873e-02 -1.04413986e-01  4.71564755e-02\n",
      "  -5.63235320e-02  8.88938904e-02 -4.60650548e-02 -4.05886536e-03\n",
      "   9.53679532e-03  8.81507620e-02  9.09720212e-02  1.14018442e-02\n",
      "  -4.08938006e-02 -3.46502624e-02  2.97761202e-01 -1.01499803e-01\n",
      "   8.13101158e-02  8.91169906e-02  1.35456389e-02  1.36549491e-02\n",
      "  -2.80102212e-02 -3.46471891e-02 -4.30636555e-02 -1.40969306e-01\n",
      "   1.85405537e-01  1.70777664e-01  9.06348154e-02  1.90114602e-01\n",
      "   3.94926220e-02 -9.64827359e-01 -1.06124982e-01  3.30277011e-02\n",
      "   3.99037823e-02  1.89232156e-02  1.61938742e-01  7.13088810e-02\n",
      "   3.49669278e-01 -5.31567298e-02 -6.86736032e-03 -2.70788223e-02\n",
      "   7.73044303e-02  1.94590807e-01 -6.82105646e-02  5.87086678e-02\n",
      "  -7.39908218e-02 -1.15649335e-01  1.79650366e-01  2.54385900e-02\n",
      "  -7.95965716e-02 -3.80479358e-02  1.03241257e-01 -2.39092167e-02\n",
      "  -4.05745283e-02 -1.30441366e-02 -1.30716473e-01  6.88661411e-02\n",
      "  -1.43181933e-02  1.08351139e-02 -4.88594472e-02  6.29450800e-03\n",
      "   6.07596934e-02  1.34349363e-02 -4.17040735e-02 -1.68203935e-01\n",
      "  -7.73942918e-02 -6.37621656e-02  6.51393458e-03 -2.46015508e-02\n",
      "   1.65683609e-02 -9.84072536e-02  1.53859273e-01 -2.51294434e-01\n",
      "   6.91477507e-02 -4.13409770e-02  7.63879865e-02  8.96484591e-03\n",
      "   1.76525097e-02  1.04491517e-01 -7.19800144e-02 -7.86430389e-02\n",
      "   3.34838927e-02  2.35691797e-02 -4.70517799e-02  1.24769911e-01\n",
      "   4.47103567e-02  5.42718470e-02 -2.95950565e-02  1.98591463e-02\n",
      "  -7.20871091e-02  1.05335917e-02  1.94937214e-01  3.29071172e-02\n",
      "   1.40077755e-01  1.63858965e-01 -9.31284651e-02  1.53130190e-02\n",
      "   1.23472631e-01 -9.36963707e-02 -2.11944617e-03  1.14854708e-01\n",
      "   1.30785415e-02  2.52612699e-02 -6.52393997e-02 -5.08368202e-03\n",
      "  -7.60914534e-02  3.81375849e-02 -1.66122559e-02  1.18004479e-01\n",
      "   2.82324869e-02 -1.38749704e-01  1.09304838e-01  3.25529054e-02\n",
      "   2.21897401e-02 -6.90579694e-03 -2.90670276e-01  2.80398577e-02\n",
      "  -6.25753254e-02 -2.43788660e-02 -4.39586937e-02 -6.21943083e-03\n",
      "   1.03353627e-01  1.56351864e-01  1.24495942e-02 -8.47700164e-02\n",
      "  -2.88971141e-02  1.65439118e-02 -5.48639782e-02  2.25647576e-02\n",
      "  -4.82706800e-02  2.05043703e-02  4.42527467e-03 -1.09061226e-02\n",
      "  -4.74255392e-03 -2.15527602e-03 -1.92634538e-02  1.01791166e-01\n",
      "  -2.36970112e-01  2.84680282e-03  2.32381392e-02 -4.56574596e-02\n",
      "  -4.87259729e-03  4.84357849e-02  6.27820313e-01  7.30005026e-01\n",
      "   1.94300339e-01  1.78300872e-01  2.45784968e-02  1.03398681e-01\n",
      "  -3.53111848e-02  6.68833628e-02  8.44863728e-02  1.97656348e-01\n",
      "   3.94916721e-02 -1.21487472e-02 -1.57533690e-01  5.75264506e-02\n",
      "   8.00833553e-02  1.29483461e-01 -1.08628059e-02 -9.33906436e-02\n",
      "  -1.64703708e-02  4.68052700e-02  1.52083457e-01 -8.36354773e-03\n",
      "   9.99277160e-02  4.67998199e-02  7.63714314e-04  9.61077586e-03\n",
      "   4.76332866e-02 -1.65881496e-02 -6.03669249e-02 -4.15394530e-02\n",
      "   1.14079013e-01  3.84451598e-01 -1.23192899e-01  8.97171050e-02\n",
      "  -6.89326599e-02 -1.59120470e-01  1.55554295e-01  1.19542040e-01\n",
      "   1.68932863e-02  8.84893462e-02 -9.36450362e-02  1.21697567e-01\n",
      "   4.55459133e-02 -2.17552800e-02 -6.33228049e-02  8.19106922e-02\n",
      "   1.44170061e-01 -2.14611776e-02  7.01196864e-02  5.58969416e-02\n",
      "  -7.13053485e-03  5.38424850e-02 -6.30877241e-02  3.20494696e-02\n",
      "   2.73429286e-02 -3.98071595e-02 -2.80766580e-02 -1.08309746e-01\n",
      "   1.76405087e-01  9.46469903e-02  7.69162551e-02  1.69227585e-01\n",
      "  -9.61237699e-02  4.99688536e-02 -9.69277918e-02  8.86771083e-02\n",
      "   1.85998306e-02 -5.61705351e-01  1.98888183e-01 -2.17948258e-02\n",
      "  -3.32944095e-02 -9.92392600e-02 -5.83641184e-03 -9.69895050e-02\n",
      "   6.78791329e-02 -1.45507921e-02  7.42957592e-02 -1.10959308e-02\n",
      "   6.84731603e-02  1.67516336e-01  4.30687889e-02 -7.82611817e-02\n",
      "  -4.28653061e-02 -8.77236202e-02  1.41832419e-02 -2.21231543e-02\n",
      "  -2.74691395e-02  1.65465042e-01  1.25047028e-01 -2.23294154e-01\n",
      "  -9.26112086e-02  1.40093476e-01 -3.89523506e-02 -8.88884738e-02\n",
      "  -1.32496297e-01 -3.59956995e-02  1.78249776e-01  6.54685721e-02\n",
      "   2.55241524e-02 -3.84809962e-03 -1.06153209e-02  3.46339196e-02\n",
      "  -1.04886629e-01 -6.71081841e-02 -1.64694428e-01 -3.76466475e-02\n",
      "  -8.32663104e-03 -1.41905725e-01 -3.09336185e-02 -4.67185155e-02\n",
      "   4.65773651e-03  4.41112556e-02  1.31453425e-01  1.55443817e-01\n",
      "   1.66729651e-02  3.64428684e-02 -3.47792096e-02 -3.00108436e-02\n",
      "   5.16561791e-02  7.37383813e-02  8.07493329e-02  2.47969940e-01\n",
      "  -7.52819376e-03 -8.48517537e-01  9.02376790e-03 -8.98568854e-02\n",
      "   3.28104161e-02  5.62562943e-02 -2.32060086e-02  1.13823935e-01\n",
      "  -3.54701374e-03 -4.47324738e-02  2.79194992e-02 -8.05755053e-03\n",
      "   1.01233855e-01 -1.33921932e-02 -1.19772941e-01  4.31777760e-02\n",
      "   3.22091132e-02  8.76016244e-02 -4.22055386e-02 -2.82509755e-02\n",
      "  -4.76347692e-02 -3.33997160e-02  1.56896815e-01 -5.56984730e-02\n",
      "   2.99082156e-02  1.84179589e-01 -1.08594306e-01 -5.17978109e-02\n",
      "   3.04362569e-02  5.19419536e-02 -3.85551415e-02 -2.49923160e-03\n",
      "  -5.99769130e-02  1.58557463e-02 -6.18437305e-02 -2.56652534e-02\n",
      "   1.23148076e-01 -6.44477904e-02  2.03922600e-01 -5.26842326e-02\n",
      "  -5.87802753e-02  3.58166285e-02  1.79063350e-01  2.40289252e-02\n",
      "  -3.47976357e-01  7.35232010e-02 -1.94330350e-01  3.90215591e-02\n",
      "   5.85289532e-03 -3.06542683e-03  3.89915556e-02  9.58744716e-03\n",
      "   4.13094759e-02 -3.01273074e-03  1.09505551e-02  1.35499658e-02\n",
      "  -5.30395173e-02  4.04373882e-03 -7.74651347e-03  9.34488177e-02\n",
      "  -1.68468356e-02 -4.47971560e-03  5.46280853e-02 -9.48272869e-02\n",
      "   1.08891077e-01 -3.37170623e-02  6.00194782e-02 -4.18980531e-02\n",
      "   8.28473717e-02  5.15283309e-02 -1.46137908e-01  4.78858016e-02\n",
      "  -8.29722285e-02 -1.24479266e-04 -1.66959450e-01 -2.42693210e-03\n",
      "   5.19302674e-02  2.01871265e-02  1.23044729e-01 -1.89530045e-01\n",
      "   1.41878158e-01  3.37545536e-02  8.89509693e-02  8.62643421e-02\n",
      "   8.85030329e-02  1.13555446e-01  2.87302017e-01  8.13947916e-02\n",
      "  -1.33124664e-01 -7.74262324e-02  5.19880501e-04 -9.17809159e-02\n",
      "   3.33013982e-02 -6.88454658e-02 -6.04220899e-03 -1.77647863e-02\n",
      "   1.00518033e-01 -4.47322428e-02  8.66738856e-02 -2.24557407e-02\n",
      "   4.75350469e-02  8.34925249e-02 -7.92174190e-02 -2.09952462e-02\n",
      "  -2.60616094e-02  9.78788957e-02  2.64494848e-02 -3.09597328e-02\n",
      "   8.87937695e-02  3.98603827e-02 -8.64864141e-03  7.37167895e-02\n",
      "   2.88684458e-01  5.53805567e-02  1.16108477e-01 -2.21918568e-01\n",
      "   3.25159654e-02  2.25174595e-02 -3.07922125e-01 -7.70608988e-03\n",
      "   3.46985981e-02 -2.94805411e-02 -7.29358867e-02  8.02739114e-02\n",
      "   1.15018710e-01  1.11984499e-01 -7.51240551e-02  3.22397538e-02\n",
      "   1.55419692e-01  2.00633854e-01 -1.52149319e-03 -8.76086652e-02\n",
      "   1.10759668e-01  3.58829573e-02  2.36467272e-01 -2.15034127e-01\n",
      "   9.71368885e+00  4.67213877e-02  3.78131084e-02  1.29085258e-01\n",
      "   1.28908074e-02 -4.95881715e-04  6.91437274e-02 -2.14192897e-01\n",
      "  -7.96380192e-02  6.84681982e-02  8.41879323e-02  8.32047909e-02\n",
      "   5.87624647e-02 -1.32510796e-01 -1.37384059e-02  7.48643577e-02\n",
      "  -5.70431463e-02  6.28166571e-02  2.39250567e-02  7.41592124e-02\n",
      "   7.33860359e-02  3.21391933e-02 -7.60645494e-02  6.56264603e-01\n",
      "   1.17284898e-02  1.09511614e-02  2.30813339e-01 -2.03024913e-02\n",
      "  -3.09112072e-02 -4.39789779e-02 -1.03611648e-01  1.01647839e-01\n",
      "   1.69338584e-02 -2.29586158e-02  1.20095059e-01  3.90441753e-02\n",
      "  -1.87874548e-02  1.55448630e-01  9.71014500e-02  2.82430407e-02\n",
      "   6.99662343e-02  9.16445851e-02 -6.87864348e-02 -1.89068224e-02\n",
      "   3.88671979e-02 -8.03253129e-02  2.99799237e-02  1.02045394e-01\n",
      "  -9.53403637e-02  1.16105996e-01 -5.41160489e-03 -1.12360176e-02\n",
      "   1.38939500e-01 -8.20789635e-02 -9.62624475e-02  2.85467394e-02\n",
      "   6.95847049e-02 -5.11663295e-02  2.68556513e-02  1.70494318e-01\n",
      "   3.45160738e-02  1.98706493e-01  5.39215319e-02 -8.36721510e-02\n",
      "  -9.29906964e-03  7.57657886e-02  4.00402918e-02  1.31068509e-02\n",
      "  -2.28981018e-01 -3.19366939e-02  2.15979815e-02 -8.81305039e-02\n",
      "  -7.61884749e-02  4.88140881e-02 -8.47942755e-02 -7.91857839e-02\n",
      "   4.14249271e-01  1.25131048e-02  1.03280693e-02 -2.39219144e-02\n",
      "  -1.16913551e-02  9.04498026e-02  4.55613062e-02  8.86727870e-02\n",
      "  -1.01130486e-01  1.16962083e-01 -4.33561988e-02 -7.58592114e-02\n",
      "  -3.30062546e-02  1.52042471e-02  3.53690684e-02  1.11017644e-01\n",
      "   3.60735618e-02  5.47149517e-02  9.01426896e-02 -4.78034616e-02\n",
      "  -3.57177109e-02  2.38661375e-03  3.84399332e-02 -5.32102026e-02\n",
      "  -7.09441723e-03  3.22704129e-02  5.33564128e-02 -2.85878181e-02\n",
      "   1.33977711e-01  8.91905278e-03  1.09267510e-01  5.49705420e-03\n",
      "   6.70521930e-02 -1.21812411e-01  2.45492794e-02  1.22185284e-02\n",
      "   5.07966504e-02  1.07687406e-01  4.99277972e-02 -8.57436284e-02\n",
      "   3.61440778e-02  4.03572898e-03  8.38539898e-02  8.35815594e-02\n",
      "  -3.74270380e-02  4.82927356e-03 -6.64243698e-02  9.65396315e-02\n",
      "   8.00926387e-02  5.07736355e-02 -1.93889905e-02  1.34154288e-02\n",
      "  -2.40656719e-01  1.25432368e-02 -5.33555485e-02 -3.61700617e-02\n",
      "   3.07380259e-01 -1.30017772e-01  4.13719378e-02 -8.00809264e-02\n",
      "   4.65418510e-02 -3.58892381e-02 -1.42369494e-02  8.91337991e-02\n",
      "  -4.08971384e-02  1.00000901e-02  2.07565855e-02  1.19638905e-01\n",
      "   9.67530385e-02  1.22023851e-01 -3.42093855e-02  2.60597579e-02\n",
      "   1.09287553e-01 -6.20132685e-02 -3.54849435e-02  9.13035199e-02\n",
      "   1.16801765e-02  2.96480171e-02  2.67409012e-02  2.01779362e-02\n",
      "  -6.86725378e-02  1.93769276e-01 -4.88576554e-02  8.01728070e-02\n",
      "  -2.01485194e-02 -3.44164610e-01  1.13567961e-02  1.21559076e-01\n",
      "   4.75431681e-02 -7.81377591e-03  6.96585998e-02  1.34766310e-01\n",
      "  -7.38361031e-02 -1.53358560e-02 -4.02829833e-02  3.38596329e-02\n",
      "   6.67049037e-03 -1.40581787e-01 -4.76032421e-02  6.04148880e-02\n",
      "  -9.52183083e-02 -1.57189891e-01  1.10526748e-01 -4.38290834e-02]]\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "import torch\n",
    "\n",
    "# Load the RoBERTa tokenizer and model\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
    "\n",
    "# Example medical transcript\n",
    "medical_transcript = \"Patient presented with symptoms of fever and cough. Diagnosis revealed pneumonia.\"\n",
    "\n",
    "# Tokenize the medical transcript\n",
    "inputs = tokenizer(medical_transcript, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "# Forward pass through the model\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "# Get the embeddings of the last hidden layer\n",
    "last_hidden_states = outputs.last_hidden_state\n",
    "\n",
    "# Calculate the mean embedding across all tokens\n",
    "mean_embedding = torch.mean(last_hidden_states, dim=1)\n",
    "\n",
    "# Convert the mean embedding to a numpy array\n",
    "mean_embedding_numpy = mean_embedding.numpy()\n",
    "\n",
    "print(\"Mean Embedding Shape:\", mean_embedding_numpy.shape)\n",
    "print(\"Mean Embedding:\", mean_embedding_numpy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7859eb49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Embedding Shape: (1, 512)\n",
      "Mean Embedding: [[ 1.43325632e-03  3.03820461e-01  9.98550579e-02 -7.40139186e-02\n",
      "   9.59046651e-04  6.23361059e-02 -1.76047102e-01 -4.88029495e-02\n",
      "   4.75238264e-01 -1.78186938e-01  2.60818064e-01  5.55268563e-02\n",
      "  -4.65925112e-02 -1.44470856e-01  3.17464924e+00 -1.24402113e-01\n",
      "  -1.13300875e-01 -3.44110504e-02  1.58099309e-01 -4.80108224e-02\n",
      "   2.10603801e-04  6.91224411e-02  1.36738554e-01  2.55352759e+00\n",
      "  -5.00732996e-02 -3.04256618e-01  2.45103776e-01  9.09000337e-01\n",
      "   1.28503785e-01  1.53549328e-01  9.58630741e-02 -6.45914748e-02\n",
      "   3.02465279e-02 -2.55008727e-01  3.07639062e-01  9.58694145e-02\n",
      "   3.45771573e-02  8.95791054e-02 -1.13229744e-01  1.94041535e-01\n",
      "   9.57155228e-02  1.23583777e-02 -4.18286212e-03  2.59297431e-01\n",
      "  -3.02465633e-02 -1.36698231e-01  4.35405046e-01 -1.97037101e-01\n",
      "   9.77664813e-02  1.76745251e-01  1.41536677e-02  1.48561344e-01\n",
      "  -4.76563089e-02  2.93638650e-02  7.57103637e-02 -7.89814591e-02\n",
      "   3.40653509e-02 -1.73021242e-01 -6.53917864e-02  3.85125875e-01\n",
      "  -5.45103885e-02 -1.31565362e-01  5.48662338e-03 -2.42935672e-01\n",
      "   7.81229138e-02  2.33646892e-02  1.01436421e-01  1.11343652e-01\n",
      "   5.13873696e-01  2.16531456e-01 -1.62003651e-01  2.12838501e-01\n",
      "   1.71355177e-02 -1.65108815e-01  3.76814902e-02  2.65333980e-01\n",
      "  -3.74573097e-02 -1.88458785e-01 -2.22240075e-01  2.45606720e-01\n",
      "   1.13898851e-02 -4.14884835e-02  1.02028241e-02 -1.30648911e-01\n",
      "  -3.29164416e-02 -4.74684462e-02 -4.10014652e-02  2.63090760e-01\n",
      "  -1.22713841e-01  4.01759833e-01 -2.25360230e-01 -4.36959982e-01\n",
      "   3.56669337e-01 -1.81780517e-01  4.48607169e-02  5.48783951e-02\n",
      "   3.34374756e-02 -9.27342996e-02  1.87252574e-02  1.09409727e-02\n",
      "   6.70766830e-03 -1.18134439e-01  2.15038240e-01 -4.12985608e-02\n",
      "  -6.23720549e-02  1.46297012e-02 -4.80435789e-02 -6.70671463e-02\n",
      "   7.13794976e-02 -8.13670158e-02  4.25903536e-02 -1.15081752e-02\n",
      "  -2.28331070e-02  6.63076118e-02  6.58258349e-02  5.08760065e-02\n",
      "   1.60551637e-01  2.42504954e-01  5.43727316e-02 -7.35298991e-02\n",
      "   5.21798991e-02  8.92906636e-02 -5.20912707e-02  1.03195086e-01\n",
      "  -1.89415962e-02  9.33338583e-01 -1.14811342e-02 -1.07598640e-01\n",
      "  -1.55707747e-01 -2.26607740e-01 -6.23164885e-02  1.54823348e-01\n",
      "   3.69120315e-02 -5.74977696e-02 -1.47355571e-01  1.33308604e-01\n",
      "  -3.25496823e-01  6.21925414e-01 -2.45181039e-01 -1.36856949e-02\n",
      "   1.14790741e-02  3.00198942e-01 -9.17504728e-02 -1.47166431e-01\n",
      "   1.86947241e-01  1.37007788e-01  3.53608020e-02  8.73362944e-02\n",
      "   3.02343518e-02 -8.47364247e-01  1.02334127e-01 -1.62482813e-01\n",
      "   1.57557622e-01 -1.48892418e-01 -9.23927501e-02 -2.01216564e-02\n",
      "  -2.27068625e-02  2.95073949e-02 -1.14227002e-02 -2.36369457e+01\n",
      "   3.05566788e-02  9.56685916e-02 -1.19545422e-01  1.10916071e-01\n",
      "   1.23359431e-02  8.91134962e-02  1.64487615e-01  4.85053845e-02\n",
      "  -1.25199467e-01  4.12505865e-03  7.04840571e-02  2.08714958e-02\n",
      "  -1.35055613e-02 -3.26162800e-02 -2.73763426e-02  1.72395557e-01\n",
      "   3.39042783e-01 -2.22783059e-01  5.66503927e-02  1.31935731e-01\n",
      "  -1.24498717e-02  2.48647276e-02 -5.76045364e-03 -1.94388226e-01\n",
      "  -5.68551838e-01  5.01161329e-02 -6.52466342e-02  1.21746577e-01\n",
      "   1.33401081e-02 -1.89037099e-01 -1.02923088e+01 -6.31228834e-02\n",
      "  -1.84371904e-01  2.07116455e-01 -1.54130235e-01 -1.75350145e-01\n",
      "   1.36982977e-01 -2.02510674e-02  7.32027963e-02  6.31712526e-02\n",
      "  -6.37779161e-02  3.24274935e-02 -2.86962651e-02  2.59605646e-01\n",
      "  -8.02818835e-02 -1.48992062e-01 -1.98919773e-02 -3.96452010e-01\n",
      "   7.82881752e-02 -1.80085022e-02  9.72331688e-02  6.40125945e-02\n",
      "   6.18706793e-02 -3.11947055e-02  1.95237294e-01 -1.55571744e-01\n",
      "   3.35677266e-02  7.79912900e-03  2.98112452e-01 -5.71851805e-02\n",
      "   5.24893142e-02  6.88958690e-02 -5.35296462e-02  9.28544402e-02\n",
      "  -1.80283070e-01  1.19481929e-01 -1.37928176e+00  1.57037526e-02\n",
      "   2.22992189e-02 -2.73701221e-01  2.43750855e-01  6.92456961e-02\n",
      "   5.98439053e-02  1.66466132e-01 -4.44069028e-01 -1.30694196e-01\n",
      "  -6.90964684e-02  7.67559111e-02  8.18997473e-02  3.81406426e-01\n",
      "   6.35358512e-01  1.04882210e-01 -2.68392842e-02  1.02426529e-01\n",
      "  -2.94814855e-01  5.03431678e-01 -2.80379206e-01  1.90915670e-02\n",
      "  -3.16569865e-01  1.55696318e-01  8.62470791e-02  5.09943105e-02\n",
      "   5.04007414e-02 -5.56650199e-02 -2.97782682e-02  8.51922035e-02\n",
      "   1.91912755e-01 -2.92541981e-02 -1.00941462e-02  3.50753158e-01\n",
      "  -1.39976721e-02 -6.44440129e-02  2.53058553e-01  7.81665623e-01\n",
      "  -8.89873952e-02 -3.87613438e-02  5.30519076e-02 -1.27349645e-01\n",
      "   4.05631699e-02 -9.53720510e-02 -6.93643093e-02  1.84173629e-01\n",
      "   6.06337823e-02  5.97245634e-01 -8.65745638e-03 -5.59881508e-01\n",
      "  -2.68950462e-01 -1.16732016e-01 -1.38790710e-02 -7.92783946e-02\n",
      "  -6.06924854e-02  7.89026394e-02  8.24694633e-02 -5.46796760e-03\n",
      "  -7.26986602e-02  1.74750686e-01  1.51999086e-01  1.59839630e-01\n",
      "   1.16190210e-01 -5.84725104e-02  4.47070092e-01  1.57108635e-01\n",
      "  -1.81410372e-01 -1.20270021e-01 -4.43759173e-01  2.82193542e-01\n",
      "  -4.17274944e-02  7.71515891e-02 -7.60947689e-02  5.12156427e-01\n",
      "   2.72536394e-03  3.95563245e-02  2.90688733e-03  1.24067701e-02\n",
      "  -7.87227899e-02  1.08122654e-01  4.65737768e-02 -1.95873424e-01\n",
      "   1.84773529e+00 -2.92438209e-01  2.05936860e-02  3.16509128e-01\n",
      "  -5.15320897e-01  2.97132939e-01  6.90196976e-02 -2.16516674e-01\n",
      "  -1.47954244e-02 -2.66030710e-02 -2.91259408e-01 -7.49465637e-03\n",
      "  -1.28390774e-01 -1.49827585e-01  2.25179102e-02 -3.89427096e-01\n",
      "   1.40580785e+00  5.59627637e-02  1.52556971e-01  6.50858954e-02\n",
      "  -3.36191058e-03 -3.03023189e-01 -1.77809313e-01  4.28936072e-02\n",
      "  -9.34839547e-02 -1.03033446e-01 -3.96699794e-02 -1.52751938e-01\n",
      "  -2.74639875e-01  4.01278920e-02 -1.27912700e-01 -8.19403380e-02\n",
      "  -1.23581856e-01  1.03708036e-01  7.12098181e-02 -2.03299709e-02\n",
      "  -4.41940166e-02 -1.55099258e-01 -1.02141932e-01  6.64471537e-02\n",
      "   9.77742895e-02  8.20048898e-02  8.70263353e-02 -4.76429518e-03\n",
      "   1.85194895e-01 -1.28463209e-01 -4.21943627e-02 -1.93362907e-01\n",
      "  -8.87546837e-02 -4.03476432e-02  3.50122213e-01  1.13389276e-01\n",
      "   1.69149891e-01 -2.35958328e-03  1.50801018e-01 -1.56101823e-01\n",
      "   5.03057465e-02  1.72922477e-01  1.34485319e-01 -1.58499047e-01\n",
      "   1.17009655e-02  1.37869254e-01 -5.61297461e-02  4.23942842e-02\n",
      "   5.50656505e-02  1.13653066e-02 -1.50010493e-02 -9.28069502e-02\n",
      "  -1.38528144e-03  4.46775649e-03 -2.79034190e-02 -7.60485947e-01\n",
      "   1.32758766e-01 -8.17602426e-02  2.99218819e-02 -1.10300630e-01\n",
      "   3.12698990e-01  1.03512913e-01  4.76885796e-01 -1.13627270e-01\n",
      "  -1.50766507e-01  1.70947909e-01  1.20369732e-01  8.79730955e-02\n",
      "  -2.10558418e-02 -7.13810250e-02  1.21528633e-01  8.07676166e-02\n",
      "  -1.91733032e-03  3.79407763e-01  2.74244934e-01  1.21136121e-01\n",
      "  -7.54903108e-02  2.26685509e-01  1.39878541e-01  1.10248983e-01\n",
      "  -1.08629145e-01  3.93094569e-02 -1.59302771e-01 -1.08233571e-01\n",
      "  -2.52050459e-02  6.53887689e-02  3.05207908e-01  1.11821860e-01\n",
      "  -4.16319728e-01  1.79433599e-01  3.64817642e-02  1.30317643e-01\n",
      "   7.51367137e-02  4.62520093e-01 -2.09865332e-01 -2.39603333e-02\n",
      "   6.89273849e-02  9.60748494e-02 -1.19002471e-02 -2.92647719e-01\n",
      "   1.27224714e-01 -1.48554519e-01 -1.27495244e-01  1.09795794e-01\n",
      "  -4.90226112e-02  4.57322691e-03  2.03560114e-01 -1.14605784e-01\n",
      "   5.30109778e-02 -5.90947531e-02 -1.25985503e-01  8.52998272e-02\n",
      "  -1.18768187e-02  3.27575468e-02 -5.57731241e-02 -1.40235275e-01\n",
      "  -9.13481507e-03  1.49243250e-01 -2.06854716e-02  1.82776421e-01\n",
      "   1.07842013e-01  1.12437554e-01 -7.47596286e-03 -4.82751429e-01\n",
      "   9.83722284e-02 -8.98855701e-02  6.11944310e-02  7.26143941e-02\n",
      "  -1.36041805e-01 -2.25979909e-01  1.70961455e-01 -3.43342014e-02\n",
      "  -7.85063803e-02  6.92642704e-02  5.36847264e-02  2.21070737e-01\n",
      "   6.34907484e-02 -1.17743738e-01  3.02874558e-02 -9.35399756e-02\n",
      "  -8.63480661e-03 -6.69711679e-02 -9.30790827e-02  2.91850511e-02\n",
      "  -2.63017923e-01  8.25776756e-02 -2.10601483e-02  6.27000816e-03\n",
      "  -1.42546482e-02  1.45636052e-02 -1.43828124e-01 -2.55892128e-01\n",
      "  -1.01244703e-01 -1.79981804e+00 -2.54230667e-02  1.16481900e-01\n",
      "  -5.55327117e-01  1.40512854e-01  7.92118609e-02 -1.42717108e-01\n",
      "   9.58574414e-02  7.95192868e-02 -3.55047852e-01 -2.04682976e-01\n",
      "  -1.57669365e-01  1.02306299e-01 -3.50631453e-04 -9.82809365e-02\n",
      "  -1.39005899e-01  9.46410596e-02 -7.82400593e-02  2.47930020e-01\n",
      "   1.20052241e-01 -1.44224480e-01 -1.87713370e-01 -1.36531010e-01\n",
      "  -1.53174907e-01 -7.65108168e-01  4.31655273e-02 -5.14152423e-02\n",
      "   1.77002773e-01  6.70948550e-02  1.26462728e-01  1.98954761e-01\n",
      "  -1.42752722e-01  2.34947838e-02  7.25978753e-05  8.45498145e-02]]\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5Model\n",
    "import torch\n",
    "\n",
    "# Load the T5 tokenizer and model\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "model = T5Model.from_pretrained(\"t5-small\")\n",
    "\n",
    "# Example medical transcript\n",
    "medical_transcript = \"Patient presented with symptoms of fever and cough. Diagnosis revealed pneumonia.\"\n",
    "\n",
    "# Tokenize the medical transcript\n",
    "inputs = tokenizer(medical_transcript, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "# Define a dummy output sequence\n",
    "dummy_output = torch.tensor([[1]])  # Dummy output of shape (batch_size, sequence_length)\n",
    "\n",
    "# Forward pass through the model\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_ids=inputs[\"input_ids\"], decoder_input_ids=dummy_output)\n",
    "\n",
    "# Get the embeddings of the last hidden layer\n",
    "last_hidden_states = outputs.last_hidden_state\n",
    "\n",
    "# Calculate the mean embedding across all tokens\n",
    "mean_embedding = torch.mean(last_hidden_states, dim=1)\n",
    "\n",
    "# Convert the mean embedding to a numpy array\n",
    "mean_embedding_numpy = mean_embedding.numpy()\n",
    "\n",
    "print(\"Mean Embedding Shape:\", mean_embedding_numpy.shape)\n",
    "print(\"Mean Embedding:\", mean_embedding_numpy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "302c6681",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nghuyong/ernie-1.0 were not used when initializing ErnieModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing ErnieModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ErnieModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Sentence Embeddings: (3, 768)\n",
      "[[ 0.740785   -0.27213484  0.27299964 ...  0.12558618  0.00330855\n",
      "  -1.6647937 ]\n",
      " [ 0.86112386 -0.51095754  0.19222717 ... -0.06696365 -0.13564548\n",
      "  -1.6583649 ]\n",
      " [ 0.5311943  -0.3828348   0.2244909  ...  0.07977653  0.29741117\n",
      "  -0.77518713]]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Sample medical transcript\n",
    "medical_transcript = [\n",
    "    \"Patient presented with symptoms of cough and shortness of breath.\",\n",
    "    \"Physical examination revealed elevated temperature and wheezing.\",\n",
    "    \"Diagnosis confirmed as bronchitis, prescribed antibiotics and inhaler.\"\n",
    "]\n",
    "\n",
    "# Load pre-trained ERNIE tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"nghuyong/ernie-1.0\")\n",
    "model = AutoModel.from_pretrained(\"nghuyong/ernie-1.0\")\n",
    "\n",
    "# Tokenize and encode the medical transcript\n",
    "inputs = tokenizer(medical_transcript, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "# Pass the encoded transcript through the model\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "# Extract embeddings from the last hidden states of the model\n",
    "embeddings = outputs.last_hidden_state\n",
    "\n",
    "# Average the embeddings for each token to get sentence-level embeddings\n",
    "sentence_embeddings = np.mean(embeddings.numpy(), axis=1)\n",
    "\n",
    "# Print the shape of the sentence embeddings\n",
    "print(\"Shape of Sentence Embeddings:\", sentence_embeddings.shape)\n",
    "\n",
    "print(sentence_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e096b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4152b7f2e81b41bab45cbd9be4226b00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)\"spiece.model\";:   0%|          | 0.00/760k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AlbertTokenizer, AlbertModel\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Sample medical transcript\n",
    "medical_transcript = [\n",
    "    \"Patient presented with symptoms of cough and shortness of breath.\",\n",
    "    \"Physical examination revealed elevated temperature and wheezing.\",\n",
    "    \"Diagnosis confirmed as bronchitis, prescribed antibiotics and inhaler.\"\n",
    "]\n",
    "\n",
    "# Load pre-trained ALBERT tokenizer and model\n",
    "tokenizer = AlbertTokenizer.from_pretrained('albert-base-v2')\n",
    "model = AlbertModel.from_pretrained('albert-base-v2')\n",
    "\n",
    "# Tokenize and encode the medical transcript\n",
    "inputs = tokenizer(medical_transcript, return_tensors='pt', padding=True, truncation=True)\n",
    "\n",
    "# Pass the encoded transcript through the model\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "# Extract embeddings from the last hidden states of the model\n",
    "embeddings = outputs.last_hidden_state\n",
    "\n",
    "# Average the embeddings for each token to get sentence-level embeddings\n",
    "sentence_embeddings = np.mean(embeddings.numpy(), axis=1)\n",
    "\n",
    "# Print the shape of the sentence embeddings\n",
    "print(\"Shape of Sentence Embeddings:\", sentence_embeddings.shape)\n",
    "\n",
    "print(sentence_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d4bba2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
